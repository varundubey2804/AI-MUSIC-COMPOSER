import os
from langchain_core.prompts import ChatPromptTemplate
from langchain_groq import ChatGroq

class MusicLLM:
    def __init__(self, temperature=0.7):
        self.llm = ChatGroq(
            temperature=temperature,
            groq_api_key=os.getenv("GROQ_API_KEY"),
            model_name="llama-3.1-8b-instant"
        )

    def generate_melody(self, user_input):
        prompt = ChatPromptTemplate.from_template(
            "Generate a melody based on this input: {input}. "
            "Return ONLY space-separated notes (e.g., C4 D4 E4). "
            "Do not include any conversational text."
        )
        chain = prompt | self.llm
        return chain.invoke({"input": user_input}).content.strip()

    def generate_harmony(self, melody):
        prompt = ChatPromptTemplate.from_template(
            "Create harmony chords for this melody: {melody}. "
            "Format: C4-E4-G4 F4-A4-C5. "
            "Return ONLY the chords string."
        )
        chain = prompt | self.llm
        return chain.invoke({"melody": melody}).content.strip()

    def generate_rhythm(self, melody):
        prompt = ChatPromptTemplate.from_template(
            "Suggest rhythm durations (in beats) for this melody: {melody}. "
            "Format: 1.0 0.5 0.5 2.0. "
            "Return ONLY the numbers."
        )
        chain = prompt | self.llm
        return chain.invoke({"melody": melody}).content.strip()

    def adapt_style(self, style, melody, harmony, rhythm):
        prompt = ChatPromptTemplate.from_template(
            "Adapt the following music to {style} style:\n"
            "Melody: {melody}\n"
            "Harmony: {harmony}\n"
            "Rhythm: {rhythm}\n"
            "Output a single string summary describing the changes."
        )
        chain = prompt | self.llm
        return chain.invoke({
            "style": style,
            "melody": melody,
            "harmony": harmony,
            "rhythm": rhythm
        }).content.strip()
